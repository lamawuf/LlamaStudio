#!/usr/bin/env python3
"""
–ò–º–ø–æ—Ä—Ç CSV —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π - –æ–¥–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è = –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞
"""

import csv
import glob
from collections import defaultdict
from app import app, db, Lead, City, Category

def import_all():
    with app.app_context():
        # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ä–æ–¥ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        krasnodar = City.query.filter_by(name='–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä').first()
        remont = Category.query.filter_by(name='–†–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä').first()

        if not krasnodar or not remont:
            print("–û—à–∏–±–∫–∞: –Ω–µ—Ç –≥–æ—Ä–æ–¥–∞ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
            return

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ URL
        companies = defaultdict(lambda: {'phones': set(), 'social': '', 'name': ''})

        csv_files = glob.glob("leads*.csv")
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(csv_files)} CSV —Ñ–∞–π–ª–æ–≤")

        for csv_file in csv_files:
            print(f"  üìÅ {csv_file}")
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    url = row.get('2gis_url', '')
                    phone = row.get('phone', '')
                    name = row.get('name', '–ö–æ–º–ø–∞–Ω–∏—è')
                    social = row.get('social', '')

                    if not url and not phone:
                        continue

                    # –ö–ª—é—á - URL –∏–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω
                    key = url if url else phone

                    if phone:
                        companies[key]['phones'].add(phone)
                    if name and not companies[key]['name']:
                        companies[key]['name'] = name
                    if social and not companies[key]['social']:
                        companies[key]['social'] = social
                    if url:
                        companies[key]['url'] = url

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º
        imported = 0
        for key, data in companies.items():
            phones = ', '.join(sorted(data['phones']))
            if not phones:
                continue

            url = data.get('url', '')
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ URL –ø—É—Å—Ç–æ–π –∏ —É–∂–µ –µ—Å—Ç—å —Ç–∞–∫–æ–π
            if not url:
                url = None  # NULL –≤–º–µ—Å—Ç–æ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è unique constraint

            lead = Lead(
                name=data['name'] or '–ö–æ–º–ø–∞–Ω–∏—è',
                phones=phones,
                social=data['social'],
                url_2gis=url,
                city_id=krasnodar.id,
                category_id=remont.id,
                status='waiting',
                source='2gis'
            )
            db.session.add(lead)
            imported += 1

            # –ö–æ–º–º–∏—Ç–∏–º –ø–æ –æ–¥–Ω–æ–º—É —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –¥—É–±–ª–∏
            try:
                db.session.commit()
            except:
                db.session.rollback()
                imported -= 1

        print(f"\n{'='*50}")
        print(f"  –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {imported}")
        print(f"{'='*50}\n")

if __name__ == '__main__':
    import_all()
