#!/usr/bin/env python3
"""
–°–ë–û–† –õ–ò–î–û–í ‚Äî –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π
–†–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä, —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–æ–≤–∏–∑–Ω–µ, —Ç–æ–ª—å–∫–æ –±–µ–∑ —Å–∞–π—Ç–æ–≤
"""

import csv
import time
import re
from datetime import datetime
from playwright.sync_api import sync_playwright


def main():
    leads = []
    seen_phones = set()

    print(f"\n{'='*60}")
    print("  –ö–†–ê–°–ù–û–î–ê–†–°–ö–ò–ô –ö–†–ê–ô ‚Äî —Ä–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä –±–µ–∑ —Å–∞–π—Ç–æ–≤")
    print(f"{'='*60}\n")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, args=['--start-maximized'])
        page = browser.new_page(no_viewport=True)

        # –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π
        search_url = "https://2gis.ru/krasnodar/search/—Ä–µ–º–æ–Ω—Ç%20–∫–≤–∞—Ä—Ç–∏—Ä%20–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π%20–∫—Ä–∞–π"
        page.goto(search_url)
        print("üåê –ó–∞–≥—Ä—É–∂–∞—é 2GIS ‚Äî –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π...\n")
        time.sleep(4)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–æ–≤–∏–∑–Ω–µ
        print("üìã –°—Ç–∞–≤–ª—é —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É '–ü–æ –Ω–æ–≤–∏–∑–Ω–µ'...")
        try:
            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            sort_buttons = page.locator('button, span').filter(has_text=re.compile(r'–ü–æ\s*(—Ä–µ–π—Ç–∏–Ω–≥—É|–Ω–æ–≤–∏–∑–Ω–µ|—É–º–æ–ª—á–∞–Ω–∏—é)', re.I))
            if sort_buttons.count() > 0:
                sort_buttons.first.click()
                time.sleep(1)

            # –ö–ª–∏–∫ –Ω–∞ "–ü–æ –Ω–æ–≤–∏–∑–Ω–µ"
            novizne = page.locator('button, span, div').filter(has_text=re.compile(r'^–ü–æ –Ω–æ–≤–∏–∑–Ω–µ$', re.I))
            if novizne.count() > 0:
                novizne.first.click()
                time.sleep(2)
                print("‚úÖ –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ '–ü–æ –Ω–æ–≤–∏–∑–Ω–µ' —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞\n")
            else:
                print("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ '–ü–æ –Ω–æ–≤–∏–∑–Ω–µ' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥...")
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ xpath
                page.keyboard.press('Escape')
                time.sleep(0.5)
        except Exception as e:
            print(f"‚ö†Ô∏è –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: {e}\n")

        current_page = 1
        max_pages = 999  # –î–æ –∫–æ–Ω—Ü–∞
        total_checked = 0

        while current_page <= max_pages:
            print(f"\n{'‚îÄ'*50}")
            print(f"üìÑ –°–¢–†–ê–ù–ò–¶–ê {current_page}")
            print(f"{'‚îÄ'*50}")

            # –°–∫—Ä–æ–ª–ª–∏–º —Å–ø–∏—Å–æ–∫ —á—Ç–æ–±—ã –ø–æ–¥–≥—Ä—É–∑–∏–ª–∏—Å—å –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏
            try:
                list_container = page.locator('div[class*="searchResults"], div[class*="_list"]').first
                for _ in range(5):
                    list_container.evaluate('el => el.scrollBy(0, 500)')
                    time.sleep(0.3)
            except:
                pass

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–æ–º–ø–∞–Ω–∏–π
            cards = page.locator('a[href*="/firm/"]').all()

            # –§–∏–ª—å—Ç—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
            firm_links = []
            seen_hrefs = set()
            for card in cards:
                try:
                    href = card.get_attribute('href')
                    if href and '/firm/' in href and 'tab' not in href and href not in seen_hrefs:
                        seen_hrefs.add(href)
                        firm_links.append(card)
                except:
                    pass

            print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(firm_links)}")

            if len(firm_links) == 0:
                print("   ‚ö†Ô∏è –ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –≤–æ–∑–º–æ–∂–Ω–æ –∫–æ–Ω–µ—Ü")
                break

            # –ö–ª–∏–∫–∞–µ–º –Ω–∞ –∫–∞–∂–¥—É—é –∫–∞—Ä—Ç–æ—á–∫—É
            page_leads_before = len(leads)

            for i, card in enumerate(firm_links):
                try:
                    total_checked += 1
                    card.scroll_into_view_if_needed()
                    time.sleep(0.2)
                    card.click()
                    time.sleep(1)

                    # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
                    parse_company(page, leads, seen_phones, total_checked)

                except Exception as e:
                    continue

            page_leads = len(leads) - page_leads_before
            print(f"\n   üìä –°—Ç—Ä–∞–Ω–∏—Ü–∞ {current_page}: +{page_leads} –ª–∏–¥–æ–≤ (–≤—Å–µ–≥–æ: {len(leads)})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ –∫–∞–∂–¥—ã–µ 5 —Å—Ç—Ä–∞–Ω–∏—Ü
            if current_page % 5 == 0 and leads:
                save_leads(leads, interim=True)

            # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            next_page_found = False

            # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º –Ω–æ–º–µ—Ä —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            try:
                next_num = str(current_page + 1)
                next_btn = page.locator(f'a, button, span').filter(has_text=re.compile(f'^{next_num}$'))
                if next_btn.count() > 0:
                    next_btn.first.click()
                    time.sleep(2)
                    current_page += 1
                    next_page_found = True
            except:
                pass

            # –ú–µ—Ç–æ–¥ 2: –°—Ç—Ä–µ–ª–∫–∞ –≤–ø—Ä–∞–≤–æ
            if not next_page_found:
                try:
                    next_arrow = page.locator('[aria-label*="–°–ª–µ–¥—É—é—â–∞—è"], [aria-label*="Next"], button:has-text("‚Ä∫"), a:has-text("‚Ä∫")')
                    if next_arrow.count() > 0:
                        next_arrow.first.click()
                        time.sleep(2)
                        current_page += 1
                        next_page_found = True
                except:
                    pass

            if not next_page_found:
                print("\nüèÅ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞!")
                break

        browser.close()

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_leads(leads, interim=False)


def parse_company(page, leads, seen_phones, num):
    """–ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –æ—Ç–∫—Ä—ã—Ç–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏"""

    try:
        # –ù–∞–∑–≤–∞–Ω–∏–µ
        name = "–ö–æ–º–ø–∞–Ω–∏—è"
        try:
            h1 = page.query_selector('h1')
            if h1:
                name = h1.inner_text().strip()
        except:
            pass

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–∞–π—Ç –°–ù–ê–ß–ê–õ–ê
        SOCIALS = {
            'vk.com': 'VK', 'vk.ru': 'VK',
            't.me': 'Telegram', 'telegram.me': 'Telegram',
            'wa.me': 'WhatsApp', 'whatsapp.com': 'WhatsApp',
            'instagram.com': 'Instagram',
            'youtube.com': 'YouTube',
            'ok.ru': 'OK',
            'taplink.cc': 'Taplink',
            'linktree': 'Linktree',
        }
        NOT_A_SITE = list(SOCIALS.keys()) + [
            '2gis', 'facebook', 'fb.com', 'tiktok', 'rutube',
            'viber', 'yandex', 'google', 'mail.ru', 'avito'
        ]

        has_real_site = False
        found_socials = []

        links = page.query_selector_all('a')
        for link in links:
            try:
                text = (link.inner_text() or '').strip().lower()
                href_link = (link.get_attribute('href') or '').lower()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ü—Å–µ—Ç–∏
                for key, label in SOCIALS.items():
                    if key in href_link or key in text:
                        if label not in found_socials:
                            found_socials.append(label)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∞–π—Ç (–¥–æ–º–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ)
                if re.match(r'^[a-z–∞-—è—ë0-9][a-z–∞-—è—ë0-9\-\.]*\.(ru|com|—Ä—Ñ|pro|su|net|org|biz|info|online|site|store|shop)$', text):
                    if not any(s in text for s in NOT_A_SITE):
                        has_real_site = True

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∞–π—Ç –≤ href
                if 'http' in href_link and not any(s in href_link for s in NOT_A_SITE):
                    # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∞–π—Ç
                    domain_match = re.search(r'https?://([^/]+)', href_link)
                    if domain_match:
                        domain = domain_match.group(1).lower()
                        if '.' in domain and not any(s in domain for s in NOT_A_SITE):
                            has_real_site = True
            except:
                continue

        if has_real_site:
            print(f"   {num}. ‚è≠ {name[:40]} ‚Äî –ï–°–¢–¨ –°–ê–ô–¢")
            return

        # –¢–µ–ª–µ—Ñ–æ–Ω
        phone = None
        phone_els = page.query_selector_all('a[href^="tel:"]')
        for phone_el in phone_els:
            href = phone_el.get_attribute('href')
            if not href:
                continue

            phone_raw = re.sub(r'[^\d+]', '', href.replace('tel:', ''))
            if phone_raw.startswith('8') and len(phone_raw) == 11:
                phone_raw = '+7' + phone_raw[1:]
            elif phone_raw.startswith('7') and len(phone_raw) == 11:
                phone_raw = '+' + phone_raw

            if len(phone_raw) >= 11 and phone_raw not in seen_phones:
                phone = phone_raw
                seen_phones.add(phone)
                break

        if not phone:
            print(f"   {num}. ‚ö†Ô∏è {name[:40]} ‚Äî –Ω–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–∞")
            return

        # URL –∫–∞—Ä—Ç–æ—á–∫–∏
        current_url = page.url

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–∏–¥–∞
        social_str = ', '.join(found_socials) if found_socials else ''
        leads.append({
            'name': name,
            'phone': phone,
            'social': social_str,
            '2gis_url': current_url
        })

        social_info = f" [{social_str}]" if social_str else ""
        print(f"   {num}. ‚úÖ {name[:40]}{social_info}")
        print(f"       üìû {phone}")

    except Exception as e:
        print(f"   {num}. ‚ùå –û—à–∏–±–∫–∞: {e}")


def save_leads(leads, interim=False):
    if not leads:
        if not interim:
            print("\n‚ùå –ù–∏—á–µ–≥–æ –Ω–µ —Å–æ–±—Ä–∞–Ω–æ")
        return

    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    suffix = "_interim" if interim else ""
    filename = f"leads_krai_{timestamp}{suffix}.csv"

    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['name', 'phone', 'social', '2gis_url'])
        writer.writeheader()
        writer.writerows(leads)

    if interim:
        print(f"\n   üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {filename}")
    else:
        print(f"\n{'='*60}")
        print(f"  ‚úÖ –°–û–ë–†–ê–ù–û: {len(leads)} –ª–∏–¥–æ–≤ –ë–ï–ó –°–ê–ô–¢–û–í")
        print(f"  üìÅ –§–∞–π–ª: {filename}")
        print(f"{'='*60}\n")


if __name__ == '__main__':
    main()
